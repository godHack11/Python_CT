L1 Regularization, L2 Regularization, ElasticNet Regularization

* L1 Regularization (Lasso Regression)
  L1 regularization is a technique that adds a penalty equal to the absolute value of the coefficients to the loss function. It helps prevent overfitting and can also perform feature 
  selection by shrinking some coefficients exactly to zero.

* L2 Regularization (Ridge Regression)
  L2 regularization is a technique that adds a penalty equal to the square of the coefficients to the loss function. It prevents overfitting by discouraging large coefficient values, but
  it does not reduce any coefficient to zero.

*  ElasticNet Regularization
   ElasticNet regularization combines both L1 and L2 penalties in the loss function. It helps when there are many correlated features and provides a balance between feature selection 
   (L1) and coefficient shrinkage (L2).






