# Probability Distributions, Conditional Probability, Bayes' Theorem, Central Limit Theorem, Hypothesis Testing, Confidence Intervals, 
# Maximum Likelihood Estimation, Bayesian Inference


# Probability Distributions
# A probability distribution describes how probabilities are distributed over values.

# Types
# Discrete Distributions (countable outcomes)
# Binomial Distribution: Success/failure over trials.
# Poisson Distribution: Events in a fixed interval.
# Continuous Distributions (infinite outcomes)
# Normal Distribution (Gaussian): Bell-shaped curve.
# Exponential Distribution: Time between events.

# Conditional Probability
# Probability of event A occurring given that B has occurred:
# P(A \mid B) = \frac{P(A \cap B)}{P(B)}
# Real-life example: Probability of being hired (A), given that you passed an exam (B).


# Bayes’ Theorem 
# Bayes’ Theorem is a fundamental formula in probability theory that helps you update the probability of an event based on new evidence.
# It connects the conditional probability of two events.

# The Formula
# P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}


# Central Limit Theorem (CLT)
# For a large enough sample size, the sampling distribution of the mean of any population becomes approximately normal, regardless of 
# the original distribution.
# Used to
# Construct confidence intervals
# Perform hypothesis testing


# Hypothesis Testing
# Used to test assumptions (hypotheses) about a population.
# Steps
# Set null hypothesis H_0 (e.g., “mean = 50”)
# Set alternate hypothesis H_1
# Choose significance level \alpha (e.g., 0.05)
# Calculate test statistic
# Compare with critical value or p-value
# Reject H_0 if p-value < α.


# Confidence Intervals (CI)
# Gives a range of values that is likely to contain the population parameter.
# \text{CI} = \bar{x} \pm z \cdot \frac{\sigma}{\sqrt{n}}
# Example: “We are 95% confident that the true mean lies between 48.2 and 51.8”

# Maximum Likelihood Estimation (MLE)
# Estimates parameters of a statistical model by maximizing the likelihood that the observed data occurred.
# Used in
# Regression
# Logistic models
# Hidden Markov models


# Bayesian Inference
# Uses Bayes’ Theorem to update probability as new evidence comes in.
# \text{Posterior} \propto \text{Prior} \times \text{Likelihood}
# Incorporates prior beliefs
# Opposite of frequentist inference
# Used in probabilistic models like Naive Bayes, Bayesian networks



